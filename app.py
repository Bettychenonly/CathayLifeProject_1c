# app.py - å®Œæ•´ UI ç‰ˆæœ¬ï¼ˆå«æ­¥é©Ÿå°å¼•èˆ‡é ç±¤ï¼‰
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from datetime import datetime
from tensorflow.keras.models import load_model
from sklearn.preprocessing import OrdinalEncoder, StandardScaler
import joblib
import os

st.set_page_config(page_title="åœ‹æ³°äººå£½ - ç”¨æˆ¶è¡Œç‚ºé æ¸¬å·¥å…·", layout="centered", initial_sidebar_state="collapsed")

# ========== åˆå§‹åŒ– Session State ==========
if "raw_uploaded_data" not in st.session_state:
    st.session_state.raw_uploaded_data = None
if "filtered_input_data" not in st.session_state:
    st.session_state.filtered_input_data = None
if "prediction_data" not in st.session_state:
    st.session_state.prediction_data = None
if "filtered_prediction_data" not in st.session_state:
    st.session_state.filtered_prediction_data = None

# ========== æ¨¡å‹èˆ‡å‰è™•ç†è¼‰å…¥ ==========
@st.cache_resource
def load_model_and_preprocessor():
    log = []
    model = load_model("model_0615")
    log.append("âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ")

        class SequencePreprocessor:
        def __init__(self, cat_features, num_features, seq_len=10):
            self.cat_features = cat_features
            self.num_features = num_features
            self.seq_len = seq_len
            self.ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)
            self.scaler = StandardScaler()
            self.num_categories = {}

        def transform(self, df):
            df[self.cat_features] = self.ordinal_encoder.transform(df[self.cat_features].astype(str)) + 2
            df['staytime'] = np.log1p(df['staytime'].fillna(0))
            df['revisit_count'] = np.log1p(df['revisit_count'])
            df[['staytime', 'revisit_count']] = self.scaler.transform(df[['staytime', 'revisit_count']])
            return df

    # âœ… åˆå§‹åŒ– preprocessorï¼ˆå¾å‰é¢ .pkl æ‹†å‡ºé‚è¼¯ï¼‰
    # è¼‰å…¥åŒ…å« encoderã€scalerã€transform æ–¹æ³•çš„å®Œæ•´å‰è™•ç†å™¨
            preprocessor = joblib.load("sequence_preprocessor.pkl")
            log.append("âœ… å‰è™•ç†å™¨è¼‰å…¥æˆåŠŸ")
            return model, preprocessor, log

# ========== å‰è™•ç†å‡½å¼ ==========
def clean_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df = df[~(df['action'].isna() & (df['action_group'] == 'å…¶ä»–'))]
    df['action'].fillna(df['action_group'], inplace=True)
    df['source'] = df['source'].fillna('None')
    df['medium'] = df['medium'].fillna('None')
    df['staytime'] = df['staytime'].fillna(0)
    df['has_shared'] = df['has_shared'].fillna(False)
    return df

# ========== é æ¸¬å‡½å¼ ==========
def preprocess_and_predict(df, model, preprocessor):
    df = clean_dataframe(df)
    X = preprocessor.transform(df)
    y_pred = model.predict(X)
    y_pred_action = np.argmax(y_pred[0], axis=1)
    y_pred_online = y_pred[1].flatten()
    y_pred_o2o = y_pred[2].flatten()
    y_pred_action_conf = np.max(y_pred[0], axis=1)
    label_encoder = preprocessor.label_encoder_action_group
    pred_action_labels = label_encoder.inverse_transform(y_pred_action)
    df_result = df.copy()
    df_result["Top1_next_action_group"] = pred_action_labels
    df_result["Top1_confidence"] = y_pred_action_conf
    df_result["online_conversion_prob"] = y_pred_online
    df_result["o2o_conversion_prob"] = y_pred_o2o
    return df_result

# ========== æ¬„ä½æª¢æŸ¥å‡½å¼ ==========
def validate_columns(df: pd.DataFrame, required_columns: list[str]) -> list[str]:
    missing = [col for col in required_columns if col not in df.columns]
    return missing

# ========== æ­¥é©Ÿ 1: ä¸Šå‚³è³‡æ–™ ==========
st.markdown("### æ­¥é©Ÿ 1: ä¸Šå‚³è³‡æ–™")
uploaded_file = st.file_uploader("è«‹ä¸Šå‚³ç”¨æˆ¶è¡Œç‚ºè³‡æ–™ (CSV æª”)", type=["csv"])

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    st.session_state.raw_uploaded_data = df
    required_columns = ["user_pseudo_id", "event_time", "action", "action_group", "source", "medium", "platform", "staytime", "has_shared", "revisit_count"]
    missing_cols = validate_columns(df, required_columns)
    if missing_cols:
        st.error(f"âŒ ç¼ºå°‘å¿…è¦æ¬„ä½ï¼š{', '.join(missing_cols)}")
        st.stop()
    st.success(f"âœ… æˆåŠŸè®€å– {len(df)} ç­†è³‡æ–™ï¼Œæ¬„ä½å®Œæ•´")
    with st.expander("ğŸ“Š è³‡æ–™é è¦½", expanded=False):
        st.dataframe(df.head(10), use_container_width=True)
else:
    st.stop()

# ========== æ­¥é©Ÿ 2: æ¨¡å‹èˆ‡è³‡æ–™è¼‰å…¥ ==========
st.markdown("### æ­¥é©Ÿ 2: è¼‰å…¥æ¨¡å‹èˆ‡å‰è™•ç†")
with st.spinner("æ­£åœ¨è¼‰å…¥æ¨¡å‹..."):
    model, preprocessor, logs = load_model_and_preprocessor()
st.success("âœ… æ¨¡å‹èˆ‡å‰è™•ç†å™¨è¼‰å…¥æˆåŠŸ")
with st.expander("ğŸ§¾ è¼‰å…¥è¨˜éŒ„", expanded=False):
    for line in logs:
        st.markdown(f"- {line}")

# ========== æ­¥é©Ÿ 3: é–‹å§‹é æ¸¬ ==========
st.markdown("### æ­¥é©Ÿ 3: é–‹å§‹é æ¸¬")
if st.button("ğŸ”® é–‹å§‹é æ¸¬"):
    with st.spinner("é æ¸¬ä¸­..."):
        df_pred = preprocess_and_predict(st.session_state.raw_uploaded_data, model, preprocessor)
        st.session_state.prediction_data = df_pred
    st.success("âœ… é æ¸¬å®Œæˆï¼")
else:
    st.stop()

# ========== æ­¥é©Ÿ 4: é æ¸¬çµæœé è¦½ ==========
st.markdown("### æ­¥é©Ÿ 4: é æ¸¬çµæœé è¦½")
df_pred = st.session_state.prediction_data
st.dataframe(df_pred.head(10), use_container_width=True)

# ========== æ­¥é©Ÿ 5: åœ–è¡¨çµ±è¨ˆ ==========
st.markdown("### æ­¥é©Ÿ 5: çµ±è¨ˆåœ–è¡¨")
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š è¡Œç‚ºåˆ†ä½ˆ", "ğŸ“ˆ ä¿¡å¿ƒåˆ†æ•¸", "ğŸ” è½‰æ›åˆ†æ", "ğŸ¯ ç­–ç•¥åˆ†ä½ˆ"])

with tab1:
    chart_df = df_pred["Top1_next_action_group"].value_counts().reset_index()
    chart_df.columns = ["action_group", "count"]
    fig1 = px.bar(chart_df, x="action_group", y="count", title="Top1 é æ¸¬è¡Œç‚ºåˆ†ä½ˆ")
    fig1.update_layout(xaxis_tickangle=-45)
    st.plotly_chart(fig1, use_container_width=True)

with tab2:
    fig2 = px.histogram(
        df_pred,
        x="Top1_confidence",
        nbins=20,
        title="Top1 é æ¸¬ä¿¡å¿ƒåˆ†æ•¸åˆ†ä½ˆï¼ˆäººæ•¸ï¼‰",
    )
    st.plotly_chart(fig2, use_container_width=True)

with tab3:
    fig3 = px.histogram(
        df_pred, x="online_conversion_prob", nbins=20, title="ç¶²æŠ•è½‰æ›æ©Ÿç‡åˆ†ä½ˆ"
    )
    fig4 = px.histogram(
        df_pred, x="o2o_conversion_prob", nbins=20, title="O2O é ç´„è½‰æ›æ©Ÿç‡åˆ†ä½ˆ"
    )
    st.plotly_chart(fig3, use_container_width=True)
    st.plotly_chart(fig4, use_container_width=True)

with tab4:
    st.info("å¯æ—¥å¾Œæ“´å……ç­–ç•¥æ¨è–¦é‚è¼¯ (ä¾ Top1 è¡Œç‚ºçµ¦å®šå»ºè­°)")

# ========== æ­¥é©Ÿ 6: ç¢ºèªæ¢ä»¶ä¸¦ä¸‹è¼‰ ==========
st.markdown("### æ­¥é©Ÿ 6: ç¢ºèªæ¢ä»¶ä¸¦ä¸‹è¼‰")

filtered_df = st.session_state.get("prediction_data", pd.DataFrame()).copy()
st.markdown(f"**ç›®å‰ç¬¦åˆæ¢ä»¶çš„ç”¨æˆ¶æ•¸é‡**ï¼š{len(filtered_df)} äºº")

if len(filtered_df) == 0:
    st.warning("âš ï¸ ç›®å‰æ¢ä»¶ä¸‹æ²’æœ‰ç¬¦åˆçš„ç”¨æˆ¶ï¼Œè«‹èª¿æ•´æ¢ä»¶å¾Œå†è©¦")
    st.stop()

# æ¢ä»¶é¸æ“‡
available_actions = filtered_df["Top1_next_action_group"].unique().tolist()
selected_actions = st.multiselect("ç¯©é¸é æ¸¬è¡Œç‚º", options=available_actions, default=available_actions)
conf_threshold = st.slider("ä¿¡å¿ƒåˆ†æ•¸ä¸‹é™", 0.0, 1.0, 0.3, step=0.05)

filtered_df = filtered_df[
    (filtered_df["Top1_next_action_group"].isin(selected_actions)) &
    (filtered_df["Top1_confidence"] >= conf_threshold)
]
st.session_state.filtered_prediction_data = filtered_df

# ä¸‹è¼‰å€å¡Š
today_str = datetime.now().strftime("%Y%m%d")
default_filename = f"prediction_result_{len(filtered_df)}users_{today_str}"
custom_filename = st.text_input(
    "è‡ªè¨‚æª”åï¼ˆé¸å¡«ï¼Œç³»çµ±æœƒè‡ªå‹•åŠ ä¸Š .csvï¼‰",
    value=default_filename,
    placeholder="ex: æ—…å¹³éšª_Top3_ä¿¡å¿ƒ0.3"
)

if st.button("ç¢ºèªæ¢ä»¶ä¸¦æº–å‚™ä¸‹è¼‰"):
    filename = f"{custom_filename}.csv"
    st.download_button("ğŸ“¥ ä¸‹è¼‰çµæœ CSV", filtered_df.to_csv(index=False), file_name=filename, mime="text/csv")






